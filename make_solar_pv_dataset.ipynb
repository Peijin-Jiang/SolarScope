{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hbu9_pcq4YWA"
      },
      "outputs": [],
      "source": [
        "DATADIR=\"/content/drive/MyDrive/solar_PV/data/\" # replace with your data directory\n",
        "SRCDIR=\"src/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOK8PqqL41t_"
      },
      "source": [
        "Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2FRK2F646Zn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_9GpLDz4lXT"
      },
      "outputs": [],
      "source": [
        "data = {\"image_path\": [], \"mask_path\": []}\n",
        "save_path = os.path.join(\"src/\", \"dataset_csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZrZk7Lm4iky"
      },
      "source": [
        "Process China for segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f0qis_B4rdQ",
        "outputId": "b45b0de6-449b-4df4-b894-119077a892d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collected 16259 image-mask pairs\n"
          ]
        }
      ],
      "source": [
        "data_path = os.path.join(DATADIR, \"China\")\n",
        "\n",
        "for folder in os.listdir(data_path):\n",
        "  for file_name in os.listdir(os.path.join(data_path, folder)):\n",
        "    if file_name.endswith(\"_label.bmp\"):\n",
        "      mask_path = os.path.join(data_path, folder, file_name)\n",
        "      image_path = os.path.join(data_path, folder, file_name.replace(\"_label.bmp\", \".bmp\"))\n",
        "      assert os.path.exists(image_path)\n",
        "      data[\"image_path\"].append(image_path)\n",
        "      data[\"mask_path\"].append(mask_path)\n",
        "print(\"Collected {} image-mask pairs\".format(len(data[\"image_path\"])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvVDvrLACT7n"
      },
      "source": [
        "Process Denmark for segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NglvQ1I59Lf",
        "outputId": "6657de76-ffd0-46d5-cafa-89e6ec6c26a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collected 880 image-mask pairs\n"
          ]
        }
      ],
      "source": [
        "data_path = os.path.join(DATADIR, \"Denmark\")\n",
        "\n",
        "new_pair_count = 0\n",
        "for folder in os.listdir(data_path):\n",
        "  masks_dir = os.path.join(data_path, folder, \"mask\")\n",
        "  for file_name in os.listdir(masks_dir):\n",
        "    mask_path = os.path.join(masks_dir, file_name)\n",
        "    image_path = mask_path.replace(\"mask\", \"positive\")\n",
        "    assert os.path.exists(image_path)\n",
        "    data[\"image_path\"].append(image_path)\n",
        "    data[\"mask_path\"].append(mask_path)\n",
        "    new_pair_count += 1\n",
        "print(\"Collected {} image-mask pairs\".format(new_pair_count))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X-LwT_iCj8q"
      },
      "source": [
        "Process France for segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKC9Xnp8AgNi",
        "outputId": "29bab549-7b2f-4d5e-b4ee-2ec8aed87e4e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13303/13303 [00:14<00:00, 906.87it/s]\n",
            "100%|██████████| 7685/7685 [00:08<00:00, 894.02it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collected 20988 image-mask pairs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "data_path = os.path.join(DATADIR, \"France\")\n",
        "\n",
        "new_pair_count = 0\n",
        "for folder in os.listdir(data_path):\n",
        "  if not folder.endswith(\"_all\"):\n",
        "    continue\n",
        "  masks_dir = os.path.join(data_path, folder, \"mask\")\n",
        "  file_names = os.listdir(masks_dir)\n",
        "  for file_name in tqdm(file_names):\n",
        "    mask_path = os.path.join(masks_dir, file_name)\n",
        "    image_path = mask_path.replace(\"mask\", \"img\")\n",
        "    assert os.path.exists(image_path)\n",
        "    data[\"image_path\"].append(image_path)\n",
        "    data[\"mask_path\"].append(mask_path)\n",
        "    new_pair_count += 1\n",
        "print(\"Collected {} image-mask pairs\".format(new_pair_count))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMtZURPQQfmP"
      },
      "source": [
        "Check the number of US large images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fG_vbO_Qel5",
        "outputId": "86101d1d-55e6-4c7e-fb22-fd0fb495f6f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of large images is 310 in Fresno_all, before tiling, it's 412\n",
            "The number of large images is 18 in Modesto_all, before tiling, it's 20\n",
            "The number of large images is 50 in Oxnard_all, before tiling, it's 75\n",
            "The number of large images is 85 in Stockton_all, before tiling, it's 94\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "data_path = os.path.join(DATADIR, \"US\")\n",
        "\n",
        "new_pair_count = 0\n",
        "for folder in os.listdir(data_path):\n",
        "  if not folder.endswith(\"_all\"):\n",
        "    continue\n",
        "  masks_dir = os.path.join(data_path, folder, \"mask_patches_new_x4\")\n",
        "  large_files = os.listdir(os.path.join(data_path, folder))\n",
        "  large_files = [file for file in large_files if file.endswith(\".tif\")]\n",
        "  file_names = os.listdir(masks_dir)\n",
        "  print(\"The number of large images is {} in {}, before tiling, it's {}\".format(len(file_names), folder, len(large_files)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1wA9DPjy128"
      },
      "source": [
        "Truncate US large images into patches (new, 1*4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmImONhRy1Sd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "from tqdm import tqdm\n",
        "\n",
        "SOURCE_DIR = r\"/content/drive/MyDrive/solar_PV/data/US/Fresno_all\"# replace with the dataset directory\n",
        "SAVE_MASK_DIR = os.path.join(SOURCE_DIR, \"mask_patches_x4/\")\n",
        "SAVE_ORIGINAL_DIR = os.path.join(SOURCE_DIR, \"original_patches_x4/\")\n",
        "POLYGONPATH = r\"/content/drive/MyDrive/solar_PV/data/US/Polygons/SolarArrayPolygons.geojson\" # replace with the dataset directory\n",
        "\n",
        "\n",
        "def patchify_one_image(img, target_size=128, save_dir=\"\"):\n",
        "    # get the size of the image\n",
        "    width, height = img.size\n",
        "    # extract patches\n",
        "    for i in range(0, width, target_size):\n",
        "        for j in range(0, height, target_size):\n",
        "            box = (i, j, i + target_size, j + target_size)\n",
        "            patch = img.crop(box).convert(\"RGB\")\n",
        "            # save the patch\n",
        "            patch.save(os.path.join(save_dir, f\"{i}_{j}.png\"))\n",
        "\n",
        "os.makedirs(SAVE_MASK_DIR, exist_ok=True)\n",
        "os.makedirs(SAVE_ORIGINAL_DIR, exist_ok=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # open the geojson file\n",
        "    with open(POLYGONPATH) as f:\n",
        "        polygons = json.load(f)\n",
        "\n",
        "    image_to_polygons = {}\n",
        "    for polygon in polygons[\"features\"]:\n",
        "        image_id = polygon[\"properties\"][\"image_name\"]\n",
        "        if image_id not in image_to_polygons:\n",
        "            image_to_polygons[image_id] = []\n",
        "        image_to_polygons[image_id].append(polygon)\n",
        "    all_image_ids = os.listdir(SOURCE_DIR)\n",
        "    all_image_ids = [image_id.replace(\".tif\", \"\") for image_id in all_image_ids if image_id.endswith(\".tif\")]\n",
        "    for image_id in tqdm(all_image_ids, desc=\"Extracting masks\"):\n",
        "        print(image_id)\n",
        "        if image_id + \".tif\" in os.listdir(SOURCE_DIR):\n",
        "\n",
        "            img = Image.open(os.path.join(SOURCE_DIR, image_id + \".tif\"))\n",
        "            width, height = img.size\n",
        "            # generate the mask for the whole image\n",
        "            mask = Image.new(\"L\", (width, height), 0)\n",
        "            if image_id in image_to_polygons:\n",
        "              for polygon in image_to_polygons[image_id]:\n",
        "                  coords = polygon[\"properties\"][\"polygon_vertices_pixels\"]\n",
        "                  coords = [(x, y) for x, y in coords]\n",
        "                  ImageDraw.Draw(mask).polygon(coords, outline=255, fill=255)\n",
        "\n",
        "              save_mask_dir = os.path.join(SAVE_MASK_DIR, image_id)\n",
        "              os.makedirs(save_mask_dir, exist_ok=True)\n",
        "              # process the mask\n",
        "              patchify_one_image(mask, save_dir=save_mask_dir)\n",
        "            save_original_dir = os.path.join(SAVE_ORIGINAL_DIR, image_id)\n",
        "            os.makedirs(save_original_dir, exist_ok=True)\n",
        "            # process the original image\n",
        "            patchify_one_image(img, save_dir=save_original_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm6P4cIWDxPR"
      },
      "source": [
        "Process US datasets for segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOYWRSLSDwVg",
        "outputId": "ccf76831-249e-4d0b-d1ab-b41b3a09737b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 733529/733529 [2:39:36<00:00, 76.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collected 15614 image-mask pairs\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "import os\n",
        "from multiprocessing import Pool\n",
        "\n",
        "data_path = os.path.join(DATADIR, \"US\")\n",
        "pattern = os.path.join(data_path, \"*_all\", \"mask_patches_new_x4\", \"*\", \"*.png\")\n",
        "mask_files = glob.glob(pattern)\n",
        "\n",
        "\n",
        "def process_mask(mask_patch_path):\n",
        "    image_patch_path = mask_patch_path.replace(\"mask\", \"original\")\n",
        "    if not os.path.exists(image_patch_path):\n",
        "        return None\n",
        "    # Check if the mask_patch is empty\n",
        "    mask = Image.open(mask_patch_path)\n",
        "    if mask.getbbox() is None:\n",
        "        return None\n",
        "    return (image_patch_path, mask_patch_path)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    with Pool() as pool:\n",
        "        results = list(tqdm(pool.imap_unordered(process_mask, mask_files), total=len(mask_files)))\n",
        "\n",
        "    new_pair_count = 0\n",
        "    for result in results:\n",
        "        if result is not None:\n",
        "            image_patch_path, mask_patch_path = result\n",
        "            data[\"image_path\"].append(image_patch_path)\n",
        "            data[\"mask_path\"].append(mask_patch_path)\n",
        "            new_pair_count += 1\n",
        "\n",
        "    print(\"Collected {} image-mask pairs\".format(new_pair_count))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFxNYlY0DO6e"
      },
      "source": [
        "China + Denmark + France + US datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFxUcCLgE3_V",
        "outputId": "896309b5-c159-4148-babe-d1df3ab0b112"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The total number of collected image-mask pairs is 0\n"
          ]
        }
      ],
      "source": [
        "print(\"The total number of collected image-mask pairs is {}\".format(len(data[\"image_path\"])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create fine tuning and validation dataset for segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFVyKNxHD2xT",
        "outputId": "98fad544-22ad-434e-85bf-816deaf1a095"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The total number of train data is 34314\n",
            "The total number of validation data is 3813\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define test ratio\n",
        "val_r = 0.1\n",
        "\n",
        "# Load the dataset into a DataFrame\n",
        "all_dataframe = pd.DataFrame(data)\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train_dataframe, val_dataframe = train_test_split(all_dataframe, test_size=val_r, random_state=42)\n",
        "\n",
        "# Save path\n",
        "save_path = os.path.join(\"src/\", \"dataset_csv\")\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Save train and test sets as CSV files\n",
        "train_dataframe.to_csv(os.path.join(save_path, \"train.csv\"), index=False)\n",
        "val_dataframe.to_csv(os.path.join(save_path, \"val.csv\"), index=False)\n",
        "\n",
        "# Print the total number of train and test data\n",
        "print(\"The total number of train data is {}\".format(len(train_dataframe)))\n",
        "print(\"The total number of validation data is {}\".format(len(val_dataframe)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgfYwKTsierU"
      },
      "source": [
        "Make classification dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zffOh66DGVQJ"
      },
      "outputs": [],
      "source": [
        "save_path = os.path.join(\"src/\", \"dataset_csv/classification\")\n",
        "os.makedirs(save_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All segmentation samples are positive samples for classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aaqjd0qcijmF"
      },
      "outputs": [],
      "source": [
        "positive_data_path = \"src/dataset_csv/\"\n",
        "positive, negative = [], []\n",
        "for file_name in ['train.csv', 'val.csv']:\n",
        "  df = pd.read_csv(os.path.join(positive_data_path, file_name))\n",
        "  image_paths = df['image_path'].tolist()\n",
        "  for image_path in image_paths:\n",
        "    positive.append(image_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add US negativie samples for classsification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DdFhgCDjb42",
        "outputId": "8de095be-292a-44ef-d491-c572efd9c914"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 410/410 [17:47<00:00,  2.60s/it]\n",
            "100%|██████████| 20/20 [00:50<00:00,  2.54s/it]\n",
            "100%|██████████| 75/75 [02:45<00:00,  2.21s/it]\n",
            "100%|██████████| 94/94 [03:44<00:00,  2.39s/it]\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "data_path = os.path.join(DATADIR, \"US\")\n",
        "\n",
        "new_pair_count = 0\n",
        "for folder in os.listdir(data_path):\n",
        "  if not folder.endswith(\"_all\"):\n",
        "    continue\n",
        "  image_dir = os.path.join(data_path, folder, \"original_patches_new_x4\")\n",
        "  file_names = os.listdir(image_dir)\n",
        "  for file_name in tqdm(file_names):\n",
        "    image_path = os.path.join(image_dir, file_name)\n",
        "    for image_file in os.listdir(image_path):\n",
        "      if image_file.endswith(\".png\"):\n",
        "        image_patch_path = os.path.join(image_path, image_file)\n",
        "        if image_patch_path not in positive:\n",
        "          negative.append(image_patch_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add Denmark negative samples for classification (China and France don't have negative sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMnzmBsGk3lw",
        "outputId": "01b4f3a9-6482-4286-9c22-351a9020f88c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of positive data is 38127\n",
            "The number of negative data is 951264\n"
          ]
        }
      ],
      "source": [
        "# add denmark data\n",
        "denmark_path = DATADIR + \"/Denmark\"\n",
        "for file_name in os.listdir(denmark_path):\n",
        "  image_dir = os.path.join(denmark_path, file_name, \"negative\")\n",
        "  negative_image_paths = [os.path.join(image_dir, image_name) for image_name in os.listdir(image_dir)]\n",
        "  negative.extend(negative_image_paths)\n",
        "print(\"The number of positive data is {}\".format(len(positive)))\n",
        "print(\"The number of negative data is {}\".format(len(negative)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create fine tuning and validation CSV for classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m1gs75mlhqH",
        "outputId": "d085b346-bd0e-41cc-cd6e-429ebbfd9374"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The total number of train data is 890451\n",
            "The total number of val data is 98940\n"
          ]
        }
      ],
      "source": [
        "all_classification = {\n",
        "    \"image_path\": positive + negative,\n",
        "    \"label\": [1] * len(positive) + [0] * len(negative)\n",
        "}\n",
        "\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "all_classification_df = pd.DataFrame(all_classification)\n",
        "all_classification_df.to_csv(os.path.join(save_path, \"classification.csv\"), index=False)\n",
        "\n",
        "val_r = 0.1\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_dataframe, val_dataframe = train_test_split(all_classification_df, test_size=val_r, random_state=42)\n",
        "\n",
        "train_dataframe.to_csv(os.path.join(save_path, \"train.csv\"), index=False)\n",
        "val_dataframe.to_csv(os.path.join(save_path, \"val.csv\"), index=False)\n",
        "\n",
        "print(\"The total number of train data is {}\".format(len(train_dataframe)))\n",
        "print(\"The total number of val data is {}\".format(len(val_dataframe)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
